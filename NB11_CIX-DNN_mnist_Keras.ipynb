{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 11: Introduction to Deep Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "The goal of this notebook is to introduce deep neural networks (DNNs) using the high-level Keras package. The reader will become familiar with how to choose an architecture, cost function, and optimizer in Keras. We will also learn how to train neural networks.\n",
    "\n",
    "\n",
    "# MNIST with Keras\n",
    "\n",
    "We will once again work with the MNIST dataset of hand written digits introduced in *Notebook 7: Logistic Regression (MNIST)*. The goal is to find a statistical model which recognizes and distinguishes between the ten handwritten digits (0-9).\n",
    "\n",
    "The MNIST dataset comprises $70000$ handwritten digits, each of which comes in a square image, divided into a $28\\times 28$ pixel grid. Every pixel can take on $256$ nuances of the gray color, interpolating between white and black, and hence each data point assumes any value in the set $\\{0,1,\\dots,255\\}$. Since there are $10$ categories in the problem, corresponding to the ten digits, this problem represents a generic classification task. \n",
    "\n",
    "In this Notebook, we show how to use the Keras python package to tackle the MNIST problem with the help of deep neural networks.\n",
    "\n",
    "The following code is a slight modification of a Keras tutorial, see [https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py](https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py). We invite the reader to read Sec. IX of the review to acquire a broad understanding of what the separate parts of the code do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras,sklearn\n",
    "# suppress tensorflow compilation warnings\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "seed=0\n",
    "np.random.seed(seed) # fix random seed\n",
    "tf.set_random_seed(seed)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of the Procedure\n",
    "\n",
    "Constructing a Deep Neural Network to solve ML problems is a multiple-stage process. Quite generally, one can identify the key steps as follows:\n",
    "\n",
    "* ***step 1:*** Load and process the data\n",
    "* ***step 2:*** Define the model and its architecture\n",
    "* ***step 3:*** Choose the optimizer and the cost function\n",
    "* ***step 4:*** Train the model \n",
    "* ***step 5:*** Evaluate the model performance on the *unseen* test data\n",
    "* ***step 6:*** Modify the hyperparameters to optimize performance for the specific data set\n",
    "\n",
    "We would like to emphasize that, while it is always possible to view steps 1-5 as independent of the particular task we are trying to solve, it is only when they are put together in ***step 6*** that the real gain of using Deep Learning is revealed, compared to less sophisticated methods such as the regression models or bagging, described in Secs. VII and VIII of the review. With this remark in mind, we shall focus predominantly on steps 1-5 below. We show how one can use grid search methods to find optimal hyperparameters in ***step 6***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load and Process the Data\n",
    "\n",
    "Keras can conveniently download the MNIST data from the web. All we need to do is import the `mnist` module and use the `load_data()` class, and it will create the training and test data sets or us.\n",
    "\n",
    "The MNIST set has pre-defined test and training sets, in order to facilitate the comparison of the performance of different models on the data.\n",
    "\n",
    "Once we have loaded the data, we need to format it in the correct shape. This differs from one package to the other and, as we see in the case of Keras, it can even be different depending on the backend used.\n",
    "\n",
    "While choosing the correct `datatype` can help improve the computational speed, we emphasize the rescaling step, which is necessary to avoid large variations in the minimal and maximal possible values of each feature. In other words, we want to make sure a feature is not being over-represented just because it is \"large\".\n",
    "\n",
    "Last, we cast the label vectors $y$ to binary class matrices (a.k.a. one-hot format), as explained in Sec. VII on SoftMax regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n",
      "an example of a data point with label 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 784)\n",
      "Y_train shape: (60000, 10)\n",
      "\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "# input image dimensions\n",
    "num_classes = 10 # 10 digits\n",
    "\n",
    "img_rows, img_cols = 28, 28 # number of pixels \n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "\n",
    "# reshape data, depending on Keras backend\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows*img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows*img_cols)\n",
    "    \n",
    "# cast floats to single precesion\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# rescale data in interval [0,1]\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# look at an example of data point\n",
    "print('an example of a data point with label', Y_train[20])\n",
    "plt.matshow(X_train[20,:].reshape(28,28),cmap='binary')\n",
    "plt.show()\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define the Neural Net and its Architecture\n",
    "\n",
    "We can now move on to construct our deep neural net. We shall use Keras's `Sequential()` class to instantiate a model, and will add different deep layers one by one.\n",
    "\n",
    "At this stage, we refrain from using convolutional layers. This is done further below.\n",
    "\n",
    "Let us create an instance of Keras' `Sequential()` class, called `model`. As the name suggests, this class allows us to build DNNs layer by layer. We use the `add()` method to attach layers to our model. For the purposes of our introductory example, it suffices to focus on `Dense` layers for simplicity. Every `Dense()` layer accepts as its first required argument an integer which specifies the number of neurons. The type of activation function for the layer is defined using the `activation` optional argument, the input of which is the name of the activation function in `string` format. Examples include `relu`, `tanh`, `elu`, `sigmoid`, `softmax`. \n",
    "\n",
    "In order for our DNN to work properly, we have to make sure that the numbers of input and output neurons for each layer match. Therefore, we specify the shape of the input in the first layer of the model explicitly using the optional argument `input_shape=(N_features,)`. The sequential construction of the model then allows Keras to infer the correct input/output dimensions of all hidden layers automatically. Hence, we only need to specify the size of the softmax output layer to match the number of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture created successfully!\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "def create_DNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(400,input_shape=(img_rows*img_cols,), activation='relu'))\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # soft-max layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "print('Model architecture created successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Choose the Optimizer and the Cost Function\n",
    "\n",
    "Next, we choose the loss function according to which to train the DNN. For classification problems, this is the cross entropy, and since the output data was cast in categorical form, we choose the `categorical_crossentropy` defined in Keras' `losses` module. Depending on the problem of interest one can pick any other suitable loss function. To optimize the weights of the net, we choose SGD. This algorithm is already available to use under Keras' `optimizers` module, but we could use `Adam()` or any other built-in one as well. The parameters for the optimizer, such as `lr` (learning rate) or `momentum` are passed using the corresponding optional arguments of the `SGD()` function. All available arguments can be found in Keras' online documentation at [https://keras.io/](https://keras.io/). While the loss function and the optimizer are essential for the training procedure, to test the performance of the model one may want to look at a particular `metric` of performance. For instance, in categorical tasks one typically looks at their `accuracy`, which is defined as the percentage of correctly classified data points. To complete the definition of our model, we use the `compile()` method, with optional arguments for the `optimizer`, `loss`, and the validation `metric` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully and ready to be trained.\n"
     ]
    }
   ],
   "source": [
    "def compile_model(optimizer=keras.optimizers.Adam()):\n",
    "    # create the mode\n",
    "    model=create_DNN()\n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "print('Model compiled successfully and ready to be trained.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Train the model\n",
    "\n",
    "We train our DNN in minibatches, the advantages of which were explained in Sec. IV. \n",
    "\n",
    "Shuffling the training data during training improves stability of the model. Thus, we train over a number of training epochs. \n",
    "\n",
    "Training the DNN is a one-liner using the `fit()` method of the `Sequential` class. The first two required arguments are the training input and output data. As optional arguments, we specify the mini-`batch_size`, the number of training `epochs`, and the test or `validation_data`. To monitor the training procedure for every epoch, we set `verbose=True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hadas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hadas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hadas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hadas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hadas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/hadas/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hadas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/hadas/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 18s 296us/step - loss: 0.3139 - acc: 0.9073 - val_loss: 0.1326 - val_acc: 0.9560\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.1292 - acc: 0.9634 - val_loss: 0.0972 - val_acc: 0.9705\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.0887 - acc: 0.9743 - val_loss: 0.0793 - val_acc: 0.9749\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 2s 42us/step - loss: 0.0699 - acc: 0.9797 - val_loss: 0.0749 - val_acc: 0.9780\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0556 - acc: 0.9838 - val_loss: 0.0721 - val_acc: 0.9787\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0450 - acc: 0.9862 - val_loss: 0.0722 - val_acc: 0.9782\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0410 - acc: 0.9878 - val_loss: 0.0679 - val_acc: 0.9809\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0333 - acc: 0.9892 - val_loss: 0.0694 - val_acc: 0.9811\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0296 - acc: 0.9904 - val_loss: 0.0735 - val_acc: 0.9810\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0283 - acc: 0.9910 - val_loss: 0.0844 - val_acc: 0.9799\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "# create the deep neural net\n",
    "model_DNN=compile_model()\n",
    "\n",
    "# train DNN and store training info in history\n",
    "history=model_DNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the Model Performance on the *Unseen* Test Data\n",
    "\n",
    "Next, we evaluate the model and read of the loss on the test data, and its accuracy using the `evaluate()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 20us/step\n",
      "\n",
      "Test loss: 0.0844319811314741\n",
      "Test accuracy: 0.9799\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate model\n",
    "score = model_DNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# look into training history\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylabel('model accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 6: Modify the Hyperparameters to Optimize Performance of the Model\n",
    "\n",
    "Last, we show how to use the grid search option of scikit-learn to optimize the \n",
    "hyperparameters of our model. An excellent blog on this by Jason Brownlee can be found on [https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/](https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 2s 41us/step - loss: 1.1399 - acc: 0.6573\n",
      "15000/15000 [==============================] - 0s 13us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 2s 34us/step - loss: 1.1164 - acc: 0.6667\n",
      "15000/15000 [==============================] - 0s 16us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 2s 35us/step - loss: 1.1128 - acc: 0.6706\n",
      "15000/15000 [==============================] - 0s 15us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 2s 39us/step - loss: 1.1456 - acc: 0.6565\n",
      "15000/15000 [==============================] - 0s 17us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 2s 45us/step - loss: 0.3382 - acc: 0.8995\n",
      "15000/15000 [==============================] - 0s 18us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 2s 49us/step - loss: 0.3429 - acc: 0.8998\n",
      "15000/15000 [==============================] - 0s 26us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 2s 45us/step - loss: 0.3425 - acc: 0.8990\n",
      "15000/15000 [==============================] - 0s 20us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 2s 48us/step - loss: 0.3408 - acc: 0.8989\n",
      "15000/15000 [==============================] - 0s 22us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 2s 48us/step - loss: 0.3168 - acc: 0.9080\n",
      "15000/15000 [==============================] - 0s 21us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 2s 48us/step - loss: 0.3350 - acc: 0.9028\n",
      "15000/15000 [==============================] - 0s 23us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 2s 49us/step - loss: 0.3217 - acc: 0.9068\n",
      "15000/15000 [==============================] - 0s 24us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 2s 48us/step - loss: 0.3493 - acc: 0.8976\n",
      "15000/15000 [==============================] - 0s 26us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 3s 58us/step - loss: 0.3708 - acc: 0.8902\n",
      "15000/15000 [==============================] - 0s 26us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 3s 58us/step - loss: 0.3732 - acc: 0.8889\n",
      "15000/15000 [==============================] - 0s 28us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 3s 58us/step - loss: 0.3653 - acc: 0.8925\n",
      "15000/15000 [==============================] - 0s 29us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 3s 70us/step - loss: 0.3722 - acc: 0.8891\n",
      "15000/15000 [==============================] - 1s 42us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 3s 63us/step - loss: 0.3547 - acc: 0.8954\n",
      "15000/15000 [==============================] - 0s 29us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 3s 62us/step - loss: 0.3555 - acc: 0.8958\n",
      "15000/15000 [==============================] - 0s 33us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 3s 62us/step - loss: 0.3502 - acc: 0.8964\n",
      "15000/15000 [==============================] - 1s 39us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 3s 64us/step - loss: 0.3620 - acc: 0.8931\n",
      "15000/15000 [==============================] - 0s 33us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 3s 66us/step - loss: 0.4089 - acc: 0.8809\n",
      "15000/15000 [==============================] - 1s 42us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 3s 63us/step - loss: 0.4125 - acc: 0.8780\n",
      "15000/15000 [==============================] - 1s 38us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 3s 70us/step - loss: 0.3973 - acc: 0.8843\n",
      "15000/15000 [==============================] - 1s 44us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 3s 62us/step - loss: 0.4128 - acc: 0.8789\n",
      "15000/15000 [==============================] - 1s 37us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 3s 78us/step - loss: 0.2972 - acc: 0.9132\n",
      "15000/15000 [==============================] - 1s 47us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 82us/step - loss: 0.3060 - acc: 0.9100\n",
      "15000/15000 [==============================] - 1s 40us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 4s 83us/step - loss: 0.2945 - acc: 0.9132\n",
      "15000/15000 [==============================] - 1s 46us/step\n",
      "Epoch 1/1\n",
      "45000/45000 [==============================] - 3s 76us/step - loss: 0.3058 - acc: 0.9093\n",
      "15000/15000 [==============================] - 1s 53us/step\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.2678 - acc: 0.9221\n",
      "Best: 0.954300 using {'optimizer': 'Nadam'}\n",
      "0.874133 (0.005838) with: {'optimizer': 'SGD'}\n",
      "0.954017 (0.002943) with: {'optimizer': 'RMSprop'}\n",
      "0.952033 (0.001063) with: {'optimizer': 'Adagrad'}\n",
      "0.950567 (0.002530) with: {'optimizer': 'Adadelta'}\n",
      "0.953883 (0.002983) with: {'optimizer': 'Adam'}\n",
      "0.945683 (0.003317) with: {'optimizer': 'Adamax'}\n",
      "0.954300 (0.003743) with: {'optimizer': 'Nadam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# call Keras scikit wrapper\n",
    "model_gridsearch = KerasClassifier(build_fn=compile_model, \n",
    "                        epochs=1, \n",
    "                        batch_size=batch_size, \n",
    "                        verbose=1)\n",
    "\n",
    "# list of allowed optional arguments for the optimizer, see `compile_model()`\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "# define parameter dictionary\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "# call scikit grid search module\n",
    "grid = GridSearchCV(estimator=model_gridsearch, param_grid=param_grid, n_jobs=1, cv=4)\n",
    "grid_result = grid.fit(X_train,Y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Convolutional Neural Nets with Keras\n",
    "\n",
    "We have so far considered each MNIST data sample as a $(28\\times 28,)$-long 1d vector. This approach neglects any spatial structure in the image. On the other hand, we do know that in every one of the hand-written digits there are *local* spatial correlations between the pixels, which we would like to take advantage of to improve the accuracy of our classification model. To this end, we first need to reshape the training and test input data as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "Y_train shape: (60000, 10)\n",
      "\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# reshape data, depending on Keras backend\n",
    "if keras.backend.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "print('X_train shape:', X_train.shape)\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print()\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can ask the question of whether a neural net can learn to recognize such local patterns. As we saw in Sec. X of the review, this can be achieved by using convolutional layers. Luckily, all we need to do is change the architecture of our DNN, i.e. introduce small changes to the function `create_model()`. We can also merge **Step 2** and **Step 3** for convenience: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_CNN():\n",
    "    # instantiate model\n",
    "    model = Sequential()\n",
    "    # add first convolutional layer with 10 filters (dimensionality of output space)\n",
    "    model.add(Conv2D(10, kernel_size=(5, 5),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    # add 2D pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # add second convolutional layer with 20 filters\n",
    "    model.add(Conv2D(20, (5, 5), activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # add 2D pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # flatten data\n",
    "    model.add(Flatten())\n",
    "    # add a dense all-to-all relu layer\n",
    "    model.add(Dense(20*4*4, activation='relu'))\n",
    "    # apply dropout with rate 0.5\n",
    "    model.add(Dropout(0.5))\n",
    "    # soft-max layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer='Adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the deep conv net (**Step 4**) and evaluating its performance (**Step 6**) proceeds exactly as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hadas/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.2613 - acc: 0.9184 - val_loss: 0.0758 - val_acc: 0.9824\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 68us/step - loss: 0.0946 - acc: 0.9705 - val_loss: 0.0530 - val_acc: 0.9873\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0695 - acc: 0.9788 - val_loss: 0.0428 - val_acc: 0.9895\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0617 - acc: 0.9815 - val_loss: 0.0428 - val_acc: 0.9888\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0526 - acc: 0.9841 - val_loss: 0.0316 - val_acc: 0.9917\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0497 - acc: 0.9847 - val_loss: 0.0319 - val_acc: 0.9914\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0453 - acc: 0.9859 - val_loss: 0.0304 - val_acc: 0.9923\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 0.0429 - acc: 0.9863 - val_loss: 0.0310 - val_acc: 0.9910\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 0.0412 - acc: 0.9872 - val_loss: 0.0265 - val_acc: 0.9926\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 65us/step - loss: 0.0372 - acc: 0.9885 - val_loss: 0.0262 - val_acc: 0.9922\n",
      "10000/10000 [==============================] - 0s 41us/step\n",
      "\n",
      "Test loss: 0.02620456815053476\n",
      "Test accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "# create the deep conv net\n",
    "model_CNN=create_CNN()\n",
    "\n",
    "# train CNN\n",
    "model_CNN.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "# evaliate model\n",
    "score = model_CNN.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "# print performance\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
